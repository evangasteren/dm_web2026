{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hello! I am a test cell. You can run me to see if your Python environment is working.\n",
    "# Try pressing 'Ctrl + Enter' and see if you can see the message below.\n",
    "\n",
    "print(\"If it is working, it is working. If it is not, it is not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Pandas\n",
    "\n",
    "Pandas provides data structures and functions designed to make working with structured or tabular data intuitive and flexible. Moreover, it contains data structures and data manipulation tools intended to make data processing and analysis fast and convenient in Python.\n",
    "\n",
    "It merges data manipulation capabilities found in spreadsheets and relational databases (such as SQL) with the power of Python. And it's really cool to work with.\n",
    "\n",
    "**Pandas will be a major tool throughout this course! So, this is a very important notebook. You should become friends with this notebook and dream about it tonight.**\n",
    "\n",
    "## The Dataset: Immigration to Canada from 1980 to 2013\n",
    "\n",
    "Dataset source: https://www.un.org/development/desa/pd/data/international-migration-flows\n",
    "\n",
    "In the same folder as this notebook, you will find a file called Canada.xlsx (check if you have it in the same folder locally on your machine).\n",
    "\n",
    "The dataset contains annual data on international immigrants to Canada. We will explore it throughout this class :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get started with Pandas, we need to import the library.\n",
    "# Pythonic people (cool people who work with Python) conventionally work with Pandas using the alias `pd`:\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you encounter any problems running the code above? Is your code producing any errors? Don't worry. If you have seen this message:\n",
    "\n",
    "```python\n",
    "ModuleNotFoundError: No module named 'pandas'\n",
    "```\n",
    "\n",
    "You need to install the Pandas package. To do that, open a terminal, activate the Conda environment, and install the package with the following commands:\n",
    "\n",
    "```bash\n",
    "# First, activate the Conda environment\n",
    "conda activate dm_web\n",
    "\n",
    "# Then, install the package\n",
    "pip install pandas\n",
    "pip install pyarrow  # <--- a required dependency of Pandas in the next major release. By installing it now, you can avoid annoying warning messages.\n",
    "```\n",
    "\n",
    "After installing the package, you may need to restart the notebook (click the \"Restart\" button above). After that, try to execute the cell above again.\n",
    "\n",
    "**Note: This error will appear with any new package you want to use and haven't installed. In such cases, you will need to install the packages using pip.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we are ready to go! Let's load the dataset into a Pandas dataframe:\n",
    "\n",
    "df = pd.read_excel(\"Canada.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh! Here we go again. Did your code encounter problems once more? So sad.\n",
    "\n",
    "This time, you will read the error code and try to fix it by yourself. You know, I am old, and I will not be here forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you can see the table below it means you had success! But what are all these NaN in the data?!\n",
    "# Open the Canada.xlsx file and check it structure\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that we actually have distinct sheets in our dataset: \"Regions by Citizenship\" and \"Canada by Citizenship.\"\n",
    "\n",
    "Let's focus on the \"Canada by Citizenship\" sheet. Take a look at it. What do you see in the first lines?\n",
    "\n",
    "Yes, we still have a problem; the Excel file has a header (the blue part) that is not formatted in a tabular way. So, we need to get rid of it when loading the data. Otherwise, we will load the DataFrame in the wrong way.\n",
    "\n",
    "Since you are looking at the data, try to look at the lines of the data. What do you see in the last two lines?\n",
    "\n",
    "Yes, it has some data that are not following the dataset format as well. Let's get rid of these two lines as well.\n",
    "\n",
    "*\"DataFrame? What is this?\" We will talk about that soon.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to load the dataset again. But first, let's see what options the function provides to us.\n",
    "# For this, let's use a feature provided by the notebook environment.\n",
    "# We can see the parameters of a function in a Jupyter Notebook using the '?' symbol after the function name:\n",
    "\n",
    "pd.read_excel?\n",
    "\n",
    "# Check the signature below and try to find the parameter that will allow us to define the sheet name, skip some rows and skip the footer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great! You found it. Right? Riiight?\n",
    "# Now let's load the dataset, given the sheet_name and the list of rows it should skip. And do not forget to skip the footers!\n",
    "\n",
    "# TODO: Load the dataset\n",
    "df  = pd.read_excel(\"Canada.xlsx\",  # <--- complete the call\n",
    "\n",
    "# Remove the comment from the line below to print the DataFrame\n",
    "#df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the last lines in the dataset you can take a look at the tail\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Dataframes\n",
    "\n",
    "In the line above, you created a Pandas DataFrame. A DataFrame is a two-dimensional and highly flexible data structure provided by Pandas. It is one of the most commonly used data structures for data manipulation and analysis in data science and data engineering.\n",
    "\n",
    "Throughout this course, the DataFrame will be one of our main \"data units.\" What does that mean? We will always handle the data by loading it into a DataFrame, and from there, we will use other libraries to generate all sorts of visualizations. Be friends with your DataFrames; they are very powerful and can be used not only in data visualization but also in data analysis. Let's explore a little bit of that in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When working with a dataset, it's always good to start by checking the basic information about your dataframe.\n",
    "# We can do that by using the info() method:\n",
    "\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main types stored in Pandas are float, int, bool, datetime64[ns], datetime64[ns, tz], timedelta[ns], category, and object (string). \n",
    "In addition, these types have item sizes, e.g., int64 and int32.\n",
    "\n",
    "**What are the types we have in this dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also see the size of the dataframe (rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clean the dataset to remove a few unnecessary columns. We can use the pandas drop() method for that.\n",
    "\n",
    "# First, let's create a list with the columns we want to drop.\n",
    "columns = ['AREA', 'REG', 'DEV', 'Type', 'Coverage']\n",
    "\n",
    "# Then, let's drop them.\n",
    "# In pandas, axis=0 represents rows (default), and axis=1 represents columns.\n",
    "df.drop(columns, axis=1, inplace=True)\n",
    "\n",
    "# After cleaning it up, let's see the first 10 lines.\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column names are not nice. Let's rename the columns so they can be as nice as we are.\n",
    "\n",
    "# First, let's create a dictionary mapping the old names to the new coolest ones.\n",
    "new_names = {'OdName': 'Country', 'AreaName': 'Continent', 'RegName': 'Region'}\n",
    "\n",
    "# Now, let's rename the columns.\n",
    "df.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check the names of the columns. Are they the new names?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the number of immigrants is distributed over a range of years (from 1980 to 2013). It would be interesting to have a column with the total, wouldn't it?\n",
    "\n",
    "Let's do it. Let's create a column called \"Total\" that sums up the total immigrants by country over the entire period.\n",
    "\n",
    "But first, we need to create a list with all the years we want to sum up. We could do it like this: year_columns = ['1980', '1981', '1982', '1983', '1984', '1985', ...]\n",
    "\n",
    "But there are 33 years!!! So let's be smart and create a function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finish the function below to create a list with all the years we have in the dataset.\n",
    "# Note: the years are integers\n",
    "def create_list():\n",
    "    pass  # Remove that when completing the function\n",
    "\n",
    "\n",
    "year_columns = create_list()\n",
    "\n",
    "# Check if the list has all the years we need.\n",
    "print(year_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the list we finally can create the Total Column\n",
    "df['Total'] = df[year_columns].sum(axis=1)\n",
    "\n",
    "# Remember: \n",
    "# axis=0 would sum the values vertically, resulting in a single sum for each column.\n",
    "# axis=1 sums the values horizontally, resulting in a sum for each row, which is what we want when creating a \"Total\" column for each row in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Total column\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Slicing\n",
    "\n",
    "\n",
    "## Select Column\n",
    "\n",
    "Did you see what we did in the previous cell? We indexed our DataFrame using the columns. This is called Slicing. \n",
    "We can generate subdatasets by selecting the columns we want.\n",
    "\n",
    "There are two ways to filter by column name:\n",
    "\n",
    "- Method 1: Very easy and intuitive, but only works for column names that do NOT have spaces or special characters. It will return a series (We will talk about that soon).\n",
    "```python\n",
    "    df.column_name               # returns a series\n",
    "```\n",
    "- Method 2: The one we used previously. It can filter on multiple columns.\n",
    "```python\n",
    "    df['column']                  # returns a series like df.column_name\n",
    "    df[['column 1', 'column 2']]  # returns a DataFrame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try filtering on the list of countries ('Country').\n",
    "df.Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's filter the list of countries ('Country') and the data for the years: 1980 - 1985.\n",
    "\n",
    "# TODO: Add the years.\n",
    "df[['Country', 1980]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Rows\n",
    "\n",
    "**WARNING: THIS IS A VERY IMPORTANT TOPIC!**\n",
    "\n",
    "We can also select rows. There are different ways to do that:\n",
    "\n",
    "1. Using `.loc[]` to select rows based on labels or conditions.\n",
    "    ```python\n",
    "    df.loc[row_label]  # Select a single row by its label\n",
    "    df.loc[start_label:end_label]  # Select a range of rows by their labels\n",
    "    df.loc[df['Column'] == 'Value']  # Select rows based on a condition\n",
    "    ```\n",
    "2. Using `.iloc[]` to select rows based on integer positions.\n",
    "    ```python\n",
    "    df.iloc[row_index]  # Select a single row by its integer position\n",
    "    df.iloc[start_index:end_index]  # Select a range of rows by their integer positions\n",
    "    ```\n",
    "\n",
    "3. Using Conditions: You can filter rows based on conditions using boolean indexing.\n",
    "    ```python\n",
    "    df[df['Column'] == 'Value']  # Select rows where a specific condition is met\n",
    "    ```\n",
    "4. Using `.query()`: The `.query()` method allows you to filter rows using a query expression.\n",
    "    ```python\n",
    "    df.query('Column == \"Value\"')  # Select rows based on a query expression\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do it together!\n",
    "# 1. How can we select the line of Japan?\n",
    "# 2. How can we select the countries from Asia?\n",
    "# 3. How can we select the countries from Asia that have fewer than 5K immigrants to Canada?\n",
    "# 4. How can we select the row of 2011 for the countries from Asia that have fewer than 5k immigrants?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Using .loc[], Check the number of immigrants from France for the following scenarios:\n",
    "# 1. The full row data (all columns)\n",
    "# 2. For year 2000\n",
    "# 3. For years 1990 to 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check the data from Europe for two different regions: Western and Southern.\n",
    "\n",
    "# Display the dataframe and find out how many instances (rows) are there for each one of the regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Values of a DataFrame\n",
    "\n",
    "The `sort_values()` function is used to sort a DataFrame or a Series based on one or more columns.\n",
    "\n",
    "You have to specify one or more columns by which you want to sort and the order (ascending or descending).\n",
    "\n",
    "```python\n",
    "df.sort_values(col_name, axis=0, ascending=True, inplace=False, ignore_index=False)\n",
    "```\n",
    "\n",
    "- `col_name` - the column(s) to sort by.\n",
    "- `axis` - axis along which to sort. 0 for sorting by rows (default) and 1 for sorting by columns.\n",
    "- `ascending` - to sort in ascending order (True, default) or descending order (False).\n",
    "- `inplace` - to perform the sorting operation in-place (True) or return a sorted copy (False, default).\n",
    "- `ignore_index` - to reset the index after sorting (True) or keep the original index values (False, default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort out the dataframe in descending order to find out the top 10 countries that has the most imigrations to Canada\n",
    "\n",
    "df_sorted = df.sort_values(\"Total\", ascending=False, axis=0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the top 10 countries\n",
    "#df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find out top 3 countries that contributes the most to immigration to Canda in the year 1992.\n",
    "# Display the country names with the immigrant count in this year\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
